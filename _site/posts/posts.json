[
  {
    "path": "posts/2022-09-03-now-i-see-you/",
    "title": "Now I See You!",
    "description": "Implementing Google Analytics for your website",
    "author": [],
    "date": "2022-09-03",
    "categories": [],
    "contents": "\r\nObviously, when I started floating my Portfolio as part of my job\r\nhunt, I was curious about the footfall and that is when I came across this\r\nblog on implementing Google Analytics for distill articles. And here we\r\ngo!\r\n1. Set up Google Analytics\r\naccount\r\nUse your gmail account to login to Google Analytics.\r\nCreate an account and a property. The property is the url of your\r\nwebsite you want to analyse the traffic for. Create View.\r\nNote that you can use a combination of Universal Analytics as well as\r\nGA4 as of today (3rd Sept, 2022). Universal Analytics will be phased out\r\nby mid of next year. Hence, it is better to create a combination so that\r\nyou can smoothly move to GA4.\r\nOnce the property is created, copy the Tracking Id from Admin ->\r\nAccount -> Property -> Property Settings. Include this Tracking Id\r\nin your _site.yml header as\r\ngoogle_analytics: “UA-999999999-1”\r\nYou are all set to roll. Create Custom Dashboards and Reports\r\nincluding widgets you find most useful for your business.\r\nI found the following interesting. Depending on the purpose of your\r\nwebsite, you can include data about conversion, events,\r\ncampaigns,etc.\r\nAudience - Active Users\r\nHourly/Daily/Weekly No. of users\r\nSessions by Country\r\nUsers by Time of day\r\nWhat pages do your users visit?\r\nSee a sample Report below, blank as of now. Come back to see updates\r\nhere as I explore the many features available on Google Analytics.\r\nThanks! :)\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-09-04T00:20:00+08:00",
    "input_file": {}
  },
  {
    "path": "posts/DeployMLtoAWS/",
    "title": "Deploy ML Model to AWS",
    "description": "Lifecycle Series 006: Final part of the Lifecycle series",
    "author": [],
    "date": "2022-09-02",
    "categories": [],
    "contents": "\r\nThe whole idea of developing a machine learning model is to make it\r\navailable to the business to use it. For this the models can be deployed\r\non a server or cloud so that it can be accessed over your company\r\nnetwork or the web. For this demo, we will deploy it on the cloud and\r\nlink our dashboard to it.\r\nCloud computing has democratized the Tech world by allowing people to\r\ndeploy and run their applications\r\nwithout having to purchase and manage hardware\r\nset up through UI easily\r\nPut up and pull down within minutes\r\nPay only for what you use\r\nToday, we will deploy our model that predicts Hospitalization chances\r\non AWS EC2\r\nYou can have it up and running in minutes\r\nIt is inexpensive. (look out for next post on tips to monitor and\r\nreduce cost)\r\nIt is ideal for demo purposes, not stable for production\r\nuse.\r\nIt is ideal for a single person team, SageMaker and Kubernetes\r\ntakes more time to set up and manage.\r\nSince we have decided how to deploy the model, let us now look at UI\r\noptions:\r\nPython Dash, Gradio\r\nWeb App using Flask\r\nTableau\r\nWe will choose Tableau to provide the UI so that there is minimal\r\ndevelopment work and also because Tableau allows Analytics Extensions\r\nwhich can access APIs using Tabpy. Tabpy is a python package developed\r\nand managed by Tableau. We can use this to integrate Tableau dashboard\r\nwith Machine Learning model developed using python.\r\nIn short our architecture is going to be like this:\r\n\r\nSetting up AWS EC2 instance\r\nSetting up an instance on AWS EC2 with basic configuration can be\r\nfree but the 2GB memory may cause the tabpy instance to run out of\r\nmemory. In my case, i found that there was better availability with\r\nt2.medium. Probably because my model pickle was over 1.4GB and the tabpy\r\nweb service required more bandwidth.\r\nLet us start off by launching an AWS EC2 instance using the following\r\nconfiguration\r\n\r\nWe will use ubuntu as the OS for our VM because it is considered\r\nlight weight.\r\n\r\n\r\n\r\nWe will create a key pair which allows us to SSH into our vm.\r\nRemember to use the ppk key if you are going to use putty. In this case,\r\nsince I will only be deploying the model on the instance, i will just\r\nuse the windows command prompt. Save the key for further use.\r\n\r\n\r\n\r\nFor security, we will set up the default port 22 to ssh into the vm\r\nand then we will need to allow the port 9004 which is the default port\r\nused by tabpy server to listen for requests. Note that here we have set\r\nup to accept requests from any IP. We can also restrict to a particular\r\nIP especially for the SSH security.\r\n\r\nOnce done with the configuration, launch the instance and wait for\r\nthe status to change to running.We will be using the public IP and DNS\r\nas well as the saved key pair in further steps.\r\n\r\nSetting up the server\r\nGreat! Now let us SSH into the vm from windows command prompt and do\r\nthe necessary installations. Below is the command for ssh, using the key\r\nname as well as the dns.\r\n\r\n ssh -i “tabpy_key.pem” ubuntu@ec2-54-151-241-225.ap-southeast-1.compute.amazonaws.com\r\n\r\nUbuntu comes with the latest version of Python.\r\n\r\nWe will install pip and tabpy.But first, it is good practice to\r\nupdate the environment before installation. We will use the following\r\ncommand.\r\n\r\nsudo apt-get update\r\n\r\nNow let us install pip.\r\n\r\nsudo apt-get -y install python3-pip\r\n\r\nNow let us install tabpy.\r\n\r\npip3 install tabpy\r\n\r\nAfter installing tabpy package, the ssh needs to be reinitiated to be\r\nable to run tabpy server.\r\n\r\ntabpy\r\n\r\nNow let us ssh into the vm from windows command prompt to transfer\r\nthe files. Below is the command to transfer the files\r\n\r\nscp -r -i “tabpy_001.pem” ./AWS_Files ubuntu@ec2-54-151-241-225.ap-southeast-1.compute.amazonaws.com:~/\r\n\r\nWe can see that the model pickle, pre_process pickle as well as the\r\npython script to deploy the machine learning model are moved to the\r\nvm.\r\n We can confirm that the files are on\r\nvm.\r\n\r\n\r\n\r\nLet us now run the deploy_app.py using the below command\r\n\r\npython3 deploy_app.py\r\n\r\nThe python script in deploy_app.py (below) deploys the machine\r\nlearning model on the tabpy server. Please feel free to download the\r\nscript from Github\r\n\r\nAfter running the above python script, we can verify that our\r\nfunction Hospitalization_Prediction is available on tabpy\r\nserver\r\n\r\n\r\n\r\nSettings on Tableau\r\ndashboard\r\nLet us now set up tableau to access the machine learning model from\r\nTableau Desktop - Help - Settings and Performance - Manage Analytics\r\nExtension Connection as below. The Test Connection shows a successful\r\nmessage. Yay!\r\n\r\n\r\n\r\nLet us now try out our dashboard. Click on the image below to view\r\nthe video\r\n\r\nSteps to keep Tabpy\r\nrunning on the server\r\nYou have your dashboard up an running now, but if you close your\r\nterminal, the tabpy will get terminated. In order to keep it running\r\nwhen you are not connected to the server, we can install tmux\r\nwhich is a terminal multiplexer for unix like operating systems.\r\nStop Tabpy using Cntrl X, Cntrl C\r\nInstall tmux\r\n\r\nsudo apt install tmux\r\n\r\n 3. Create new session called tabpy\r\n\r\ntmux new -s tabpy\r\n\r\n 4. Start tabpy in the new session by entering ‘tabpy’. So now\r\nthe session is active and it can be detached by typing Cntrl B, D. Now\r\nthe session is detached and the terminal can be closed, the tableau\r\ndashboard will still be able to access the ML model running on AWS\r\nEC2.\r\nTo get a list of all active sessions, use the following command\r\n\r\ntmux ls\r\n\r\n 6. In order to attach to an active session, use the following\r\ncommand\r\n\r\ntmux attach-session -t tabpy\r\n\r\n Screenshot of the terminal below for reference:\r\n\r\nThere you go! The Machine Learning model is up and running and\r\naccessible to the Tableau Dashboard from anywhere.\r\nStay peeled for other posts in the Machine Learning Project\r\nLifecycle :)\r\nReferences\r\nhttps://www.machinelearningplus.com/deployment/deploy-ml-model-aws-ec2-instance/\r\nhttps://www.youtube.com/watch?v=Xk67f45BuoA\r\nhttps://www.educative.io/answers/installing-pip3-in-ubuntu\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-09-02T11:42:17+08:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "Lifecycle Series 001 : Kickstart",
    "description": "Welcome to the first of a 6 part series covering  various steps in a Machine Learning Project Lifecycle",
    "author": [],
    "date": "2022-08-26",
    "categories": [],
    "contents": "\r\nAnalytics has become a crucial part of businesses. It plays a vital\r\nrole in helping stakeholders make objective, accurate and confident\r\ndecisions. Analytics can be of the following types, looking from the\r\npast to the future\r\nDescriptive analysis -  What happened \r\nDiagnostic analysis -  Why did it happen \r\nPredictive analysis -  What will happen \r\nPrescriptive analysis -  How can we make it happen\r\n\r\nIn this Lifecycle series, we will be following a particular use case\r\nrelated to healthcare. Now, more than ever before, healthcare domain is\r\nin the limelight. In the past few years, healthcare related decisions\r\nhave been the make or break factor for economies and countries around\r\nthe world. We have seen how different countries took different\r\napproaches and we also saw how there is no one size fits all. These are\r\nvaluable lessons that can be applied to all fields. The major lessons to\r\nbe learnt are:\r\nFor a decision for a seemingly isolated problem, you will soon\r\nrealize that there are multiple governing factors and there will be\r\nmultiple factors that are directly and indirectly impacted by this\r\ndecision.\r\nIt is important to understand not just the business problem but\r\nthe entire neighborhood of it. It is important to zoom out and ask\r\nquestions.For a Data Scientist, it is important to look beyond the data\r\nand understand the nook and corner of the related business.\r\nProblem Statement\r\nThe objective of a problem statement is to explain the current state,\r\nexplain the desired state and identify what is required to change the\r\ncurrent state to the desired state. Notice that the Problem Statement is\r\npurely, well, a problem statement and it does not include the solution\r\nor how we plan to achieve the desired from the current. The ‘how’ of it\r\nis still up for debate. It does however specify how we can measure the\r\nbenefit of the solution and at what stage we can say that we have\r\nachieved our objective.\r\nLet us formulate the problem statement for our healthcare\r\nscenario.\r\nThe Emergency Room (ER) of Hospital ABC sees hundreds of patients\r\neveryday. The ER has a process in place to triage every incoming\r\npatient. The ER Nurse will carry out some basic checks which includes\r\nmeasuring the blood pressure, temperature, oxygen level etc of the\r\npatient as well as ask a few questions about the age, pain level,\r\nexisting conditions,etc. All these are recorded and the Nurse will\r\nassign a Triage Acuity value ranging from 1-5, 1 being the highest.\r\nThe objective of this triage process is to enable the hospital system\r\nto priorities the patients so that those in need of immediate care are\r\nnot kept waiting. The patient then sees the doctor after which he may or\r\nmay not get hospitalized. Now, the hospital resources are limited -\r\nlimited number of beds, limited number of equipments, limited number of\r\nnurses. So we want to make sure that only those patients who are\r\ndefinitely in need of hospitalization are admitted. This is currently\r\ndone based on the experience of the doctor. Ah, there it is, a decision\r\nbased on gut feeling. While we have absolutely no doubt in the\r\ncapability of our doctors, we are looking at ways to improve patient\r\ncare while optimizing the utilization of hospital resources.\r\nWhat are our guiding factors at this point :\r\nProvide the best possible care to the patient\r\nAs fast as possible\r\nWithout inconveniencing the patient with unnecessary\r\ntests\r\nAvoid hospitalization if possible, this serves 2 purposes\r\nnot inconvenience the patient and reduce the cost to the\r\npatient\r\nsave the hospital resources for critical patients\r\n\r\nAvoid the patient from coming back to the ER immediately (time\r\nlimit to be defined)\r\nAvoid mortality\r\nThe dataset we are going to use for this case study has all details\r\nof patient visits to the ER, hospitalization details, discharge details.\r\nLet us focus on hospitalization for the purpose of this study.\r\nFor Machine Learning project, it is very critical to identify the\r\ndata that is available at the point of time when our model is going to\r\nbe utilized. \r\nFor example, our model is to predict if a patient who has come into\r\nthe ER will get hospitalized or not, what is the data that is\r\navailable?\r\nWe have the details recorded by the Triage nurse\r\nWe have the details of the patients previous visits\r\nWhat we do not have are the following:\r\nany details of what happens after the triage nurse has collected the\r\ndata\r\nLet us now define our Outcome column. For our case study we want to\r\nidentify the records in the data set where the patient who came to the\r\nER has been hospitalized. From the data dictionary, we know that the\r\npatients who are hospitalized are assigned a hospital admission id\r\n(hdm_id) for that particular stay. We will use this column to derive our\r\nOutcome_Hospitalization column with the following code\r\n\r\nLet us now analyse what percentage of ER patients get hospitalized\r\nusing the below code.\r\n\r\nThe hospitalization rate is 46% approx. When a patient comes to ER,\r\nby assessing the chances of the patient getting hospitalized, the\r\nmedical team can further optimize the treatment plan with the objective\r\nof avoiding hospitalization. We do understand that hospitalization\r\ncannot be always avoided even with optimized treatment. Hence, we can\r\ndecide on reducing the hospitalization rate to a 35% over a period of\r\nnext 3 months as our objective. In real life scenario, this decision\r\nwill be taken based on discussions with the stakeholders.\r\nIt is also important to define a control. In this case, in our effort\r\nto reduce hospitalization rate, we should not end up compromising on the\r\ncare. So mortality and ER Readmission will be our control.\r\nLet us now frame our Problem Statement:\r\n The current rate of Hospitalization from\r\nthe ER is 46%. This results in a large proportion of the hospital\r\nfacility being occupied, sometimes resulting in unavailability. The\r\nbusiness objective is to reduce hospitalization by providing optimum\r\ncare in the ER. The success criteria to judge whether the problem has\r\nbeen solved is, in the next 3 months, the hospitalization rate should\r\ncome down to 35% without increase in mortality rate and ER Readmission\r\nrate. \r\nWe now have the business problem, which needs to be mapped to a\r\ndata science problem.\r\n The hospital has records of\r\nhospitalizations over a period of time. Using this data, we can train a\r\nclassification model which can predict the chances that a new patient\r\nwho has come to the ER will get hospitalized. This can give insight to\r\nthe medical team regarding the hospitalization chances if the existing\r\ntreatment protocol is followed. Based on this, the team can optimize the\r\ntreatment protocol for the patient in the ER resulting in reduced\r\nhospitalization. \r\nNow we have established a direction for our data science project. We\r\nwill traverse through the rest of the project lifecycle in parts\r\nExploratory Data Analysis\r\nData Wrangling\r\nModel Training and Evaluation\r\nHyperparameter Tuning\r\nDashboard Development\r\nStay tuned for Exploratory Data Analysis\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-08-26T16:29:59+08:00",
    "input_file": {}
  }
]
